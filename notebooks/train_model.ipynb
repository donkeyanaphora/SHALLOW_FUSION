{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-3 Paper Info\n",
    "\n",
    "### Model Architectures and Hyper-Parameters\n",
    "\n",
    "| Model Name              | nparams | nlayers | dmodel | nheads | dhead | Batch Size | Learning Rate  |\n",
    "|-------------------------|---------|---------|--------|--------|-------|------------|----------------|\n",
    "| GPT-3 Small             | 125M    | 12      | 768    | 12     | 64    | 0.5M       | 6.0 × 10−4    |\n",
    "| GPT-3 Medium            | 350M    | 24      | 1024   | 16     | 64    | 0.5M       | 3.0 × 10−4    |\n",
    "| GPT-3 Large             | 760M    | 24      | 1536   | 16     | 96    | 0.5M       | 2.5 × 10−4    |\n",
    "| GPT-3 XL                | 1.3B    | 24      | 2048   | 24     | 128   | 1M         | 2.0 × 10−4    |\n",
    "| GPT-3 2.7B              | 2.7B    | 32      | 2560   | 32     | 80    | 1M         | 1.6 × 10−4    |\n",
    "| GPT-3 6.7B              | 6.7B    | 32      | 4096   | 32     | 128   | 2M         | 1.2 × 10−4    |\n",
    "| GPT-3 13B               | 13.0B   | 40      | 5140   | 40     | 128   | 2M         | 1.0 × 10−4    |\n",
    "| GPT-3 175B or “GPT-3”    | 175.0B  | 96      | 12288  | 96     | 128   | 3.2M       | 0.6 × 10−4    |\n",
    "\n",
    "**Table 2.1:** Sizes, architectures, and learning hyper-parameters (batch size in tokens and learning rate) of the models\n",
    "which we trained. All models were trained for a total of 300 billion tokens.\n",
    "\n",
    "\n",
    "**Table 2.1** shows the sizes and architectures of our 8 models. Here nparams is the total number of trainable parameters,\n",
    "nlayers is the total number of layers, dmodel is the number of units in each bottleneck layer (we always have the\n",
    "feedforward layer four times the size of the bottleneck layer, dff = 4 ∗ dmodel), and dhead is the dimension of each\n",
    "attention head. All models use a context window of nctx = 2048 tokens. We partition the model across GPUs along\n",
    "both the depth and width dimension in order to minimize data-transfer between nodes. The precise architectural\n",
    "parameters for each model are chosen based on computational efficiency and load-balancing in the layout of models\n",
    "across GPU’s. Previous work [KMH+20 ] suggests that validation loss is not strongly sensitive to these parameters\n",
    "within a reasonably broad range.\n",
    "\n",
    "#### B Details of Model Training\n",
    "\n",
    "To train all versions of GPT-3, we use **Adam** with **β1 = 0.9**, **β2 = 0.95**, and **ε = 10⁻⁸**, clip the global norm of the gradient at **1.0**, and apply **cosine decay** for the learning rate, reducing it to **10%** of its value over **260 billion tokens** (after which training continues at 10% of the original rate). There is a **linear learning rate warmup** over the first **375 million tokens**, and the batch size is gradually increased from **32k tokens** to the full value over the first **4–12 billion tokens** of training, depending on model size. Data are sampled without replacement until an epoch boundary is reached to minimize overfitting, and all models use a **weight decay of 0.1** for regularization. During training, we always use sequences of the full **2048-token context window**, packing multiple documents into a single sequence when documents are shorter than 2048, with a special **end of text token** delimiting documents to efficiently indicate that separated contexts are unrelated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/collinswestnedge/Desktop/programming/git_hub/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import getpass, os, torch, glob, re, time\n",
    "\n",
    "from transformers import GPT2LMHeadModel, get_scheduler\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "from huggingface_hub import hf_hub_download, HfApi, create_repo, Repository\n",
    "from huggingface_hub.utils import HfHubHTTPError\n",
    "\n",
    "class PTIterableDataset(IterableDataset):\n",
    "    def __init__(self, pt_files):\n",
    "        self.pt_files = pt_files\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file_path in self.pt_files:\n",
    "            data = torch.load(file_path)\n",
    "            for i in range(data[\"input_ids\"].size(0)):\n",
    "                sample = {\n",
    "                    \"input_ids\": data[\"input_ids\"][i],\n",
    "                    \"attention_mask\": data[\"attention_mask\"][i],\n",
    "                    \"files\": file_path.split('/')[-1]\n",
    "                }\n",
    "                if data.get(\"labels\") is not None:\n",
    "                    sample[\"labels\"] = data[\"labels\"][i]\n",
    "                yield sample\n",
    "\n",
    "def load_checkpoint(repo_name, token, device, file_name=\"training_state.pt\"):\n",
    "    repo_name = repo_name\n",
    "\n",
    "    training_state_path = hf_hub_download(\n",
    "        repo_id=repo_name, \n",
    "        filename=file_name,\n",
    "        token=token\n",
    "    )\n",
    "    checkpoint = torch.load(training_state_path, map_location=torch.device(device))\n",
    "    return checkpoint\n",
    "\n",
    "def get_grouped_params(model, weight_decay, no_decay=[\"bias\", \"LayerNorm.weight\"]):\n",
    "    '''handy function for setting weight decay shoutout to hugging face book '''\n",
    "    params_with_wd, params_without_wd = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        if any(nd in n for nd in no_decay):\n",
    "            params_without_wd.append(p)\n",
    "        else:\n",
    "            params_with_wd.append(p)\n",
    "    return [{'params': params_with_wd, 'weight_decay': weight_decay},\n",
    "            {'params': params_without_wd, 'weight_decay': 0.0}]\n",
    "\n",
    "\n",
    "def load_base_model(model_name, device):\n",
    "    model = torch.compile(GPT2LMHeadModel.from_pretrained(model_name))\n",
    "    return model.to(device)\n",
    "\n",
    "def initialize_optimizer(model_params, base_lr):\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model_params,\n",
    "        lr=base_lr\n",
    "    )\n",
    "    return optimizer\n",
    "\n",
    "def initialize_scheduler(optimizer, n_warmup_steps, n_training_steps):\n",
    "    lr_scheduler = get_scheduler(\n",
    "        name=\"cosine\", \n",
    "        optimizer=optimizer, \n",
    "        num_warmup_steps=n_warmup_steps, \n",
    "        num_training_steps=n_training_steps\n",
    "    )\n",
    "    return lr_scheduler\n",
    "    \n",
    "def initialize_scaler(device):\n",
    "    return torch.amp.GradScaler(\"cuda\") if device == 'cuda' else None\n",
    "\n",
    "def extract_file_numbers(filename):\n",
    "    match = re.search(r'(\\d+)', filename)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "def save_checkpoint(model, optimizer, lr_scheduler, global_step, loss_history, last_file, scaler=None):\n",
    "    checkpoint = {\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'lr_scheduler': lr_scheduler.state_dict(),\n",
    "        'global_step': global_step,\n",
    "        'losses': loss_history,\n",
    "        'batch_file': last_file,\n",
    "    }\n",
    "\n",
    "    # scaler is for GPU only since doing fp16 on GPU\n",
    "    if scaler is not None:\n",
    "        checkpoint['scaler'] = scaler.state_dict()\n",
    "\n",
    "    # checkpoint file locally so we can easily push to hub\n",
    "    torch.save(checkpoint, \"training_state.pt\")\n",
    "\n",
    "\n",
    "def create_repo_if_not_exists(repo_name, token):\n",
    "    api = HfApi(token=token)\n",
    "    try:\n",
    "        api.repo_info(repo_id=repo_name)\n",
    "        print(f\"Repository '{repo_name}' already exists.\")\n",
    "    except HfHubHTTPError as e:\n",
    "        if e.response.status_code == 404:\n",
    "            print(f\"Repository '{repo_name}' not found. Creating repository...\")\n",
    "            create_repo(repo_id=repo_name, token=token)\n",
    "            print(f\"Repository '{repo_name}' created successfully.\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "\n",
    "def push_to_hub(repo_name, token, step, max_retries=3, retry_delay=10):\n",
    "    api = HfApi(token=token)\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            # Upload the training state file.\n",
    "            api.upload_file(\n",
    "                path_or_fileobj=\"training_state.pt\",\n",
    "                path_in_repo=\"training_state.pt\",\n",
    "                repo_id=repo_name,\n",
    "                commit_message=f\"Training state at step {step}\"\n",
    "            )\n",
    "            print(\"Training state pushed successfully.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt} failed: {e}\")\n",
    "            if attempt == max_retries:\n",
    "                print(\"Max attempts reached. Exiting.\")\n",
    "                raise e\n",
    "            time.sleep(retry_delay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective size with grad accumulation: 128\n",
      "Tokens per batch (paper has roughly .5M): 131072.0\n",
      "Total Training steps 27714.125\n",
      "N warmup steps (could be 3.00% of 27714.125 training_steps) => 831 steps\n"
     ]
    }
   ],
   "source": [
    "class GPT2Config:\n",
    "    device: str = 'cpu'\n",
    "    from_checkpoint: bool = False\n",
    "    data_loader_batch_size = 4\n",
    "    warm_up_ratio: float = 0.01\n",
    "\n",
    "    n_files: int = 221713\n",
    "    rows_per_file = 16\n",
    "    tokens_per_row = 1024\n",
    "    n_tokens_per_file: int = rows_per_file*tokens_per_row # (file_batch_size x max_token_len)\n",
    "    total_tokens: int = n_files * n_tokens_per_file\n",
    "    gradient_accumulation_steps: int = 32\n",
    "    tokens_per_batch: int = (n_tokens_per_file/data_loader_batch_size) * gradient_accumulation_steps\n",
    "    print(f\"Effective size with grad accumulation: {data_loader_batch_size*gradient_accumulation_steps}\")\n",
    "    print(f\"Tokens per batch (paper has roughly .5M): {tokens_per_batch}\")\n",
    "\n",
    "    base_lr: float = 1e-4 # LR for should be 6e-4 to 2.5e-4 for gpt3 small-large\n",
    "    n_training_steps: float = total_tokens / tokens_per_batch\n",
    "    n_warmup_steps: int = int(round(n_training_steps * warm_up_ratio, 1))\n",
    "    print(f\"Total Training steps {n_training_steps}\")\n",
    "    print(f\"N warmup steps (could be {warm_up_ratio*100:.2f}% of {n_training_steps} training_steps) => {n_warmup_steps} steps\")\n",
    "\n",
    "    # beta1, beta2 = 0.9, 0.95 # these may need to be changed to fit our training assumptions\n",
    "    max_grad_norm = 1.0 # paper uses 1\n",
    "    weight_decay = .10 # i believe this still makes sense\n",
    "    num_epochs: int = 1\n",
    "\n",
    "    checkpoint_repo: str = None\n",
    "    save_file_name: str = \"training_state.pt\"\n",
    "    hf_token: str = None\n",
    "    start_file: str = None\n",
    "    save_steps = 100\n",
    "\n",
    "config = GPT2Config()\n",
    "config.from_checkpoint = True\n",
    "config.checkpoint_repo = \"cwestnedge/gpt2-test\"\n",
    "config.base_model = \"openai-community/gpt2-large\"\n",
    "config.hf_token = getpass.getpass(\"Enter your Hugging Face token: \")\n",
    "config.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "config.base_lr = 2.5e-4\n",
    "config.weight_decay = 0.0\n",
    "\n",
    "# for testing\n",
    "# config.num_epochs = 40\n",
    "# config.save_steps=10\n",
    "# config.base_lr=3e-4\n",
    "# config.n_warmup_steps= (40*.1)\n",
    "# config.gradient_accumulation_steps=1\n",
    "# config.weight_decay= 0.0\n",
    "# config.data_loader_batch_size = 2\n",
    "# config.n_training_steps=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training run from ../processed_batches/train/batch_0000.pt\n",
      "{'input_ids': tensor([[ 1925,  5889,   286,  ...,   274,  2983,  3421],\n",
      "        [  739,  4096,  3403,  ...,   349,   415, 39422]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'files': ['batch_0000.pt', 'batch_0000.pt']}\n",
      "\n",
      "Repository 'cwestnedge/gpt2-test-cpu' already exists.\n"
     ]
    }
   ],
   "source": [
    "# -------- Initialize mode, optimizer and lr_scheduler -------- \n",
    "model = load_base_model(model_name=config.base_model, device=config.device)\n",
    "model_grouped_params = get_grouped_params(model, weight_decay=config.weight_decay)\n",
    "optimizer = initialize_optimizer(model_grouped_params, base_lr=config.base_lr)\n",
    "lr_scheduler = initialize_scheduler(\n",
    "    n_warmup_steps=config.n_warmup_steps, \n",
    "    n_training_steps=config.n_training_steps, \n",
    "    optimizer=optimizer\n",
    ")\n",
    "scaler = initialize_scaler(config.device)\n",
    "\n",
    "# -------- load from checkpoint or start fresh --------\n",
    "if config.from_checkpoint: \n",
    "    checkpoint = load_checkpoint(\n",
    "        repo_name=config.checkpoint_repo,\n",
    "        token=config.hf_token,\n",
    "        device=config.device, \n",
    "        file_name=config.save_file_name\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model']) # we want to log model state dict eventually model.load_state_dict(model.state_dict())\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "    if scaler:\n",
    "        scaler.load_state_dict(checkpoint['scaler'])\n",
    "    \n",
    "    global_step = checkpoint['global_step']\n",
    "    loss_history = checkpoint['losses']\n",
    "    last_file = checkpoint['batch_file']\n",
    "    last_file = ''.join(last_file)\n",
    "\n",
    "    train_files_full = sorted(glob.glob(\"../processed_batches/train/*.pt\"), key=extract_file_numbers)\n",
    "    start_file_path = f'../processed_batches/train/{last_file}'\n",
    "    start_idx = train_files_full.index(start_file_path)\n",
    "    train_files_ = train_files_full[start_idx+1:] # fix this after testing to train_files_full[start_idx+1:]\n",
    "    print()\n",
    "    print(f'Last processed file {last_file}. Resuming run from {train_files_[0]}')\n",
    "    print(f\"{(len(train_files_)/len(train_files_full))*100:0.3f}% remaining...\")\n",
    "\n",
    "else:\n",
    "    global_step, loss_history= 0, []\n",
    "    train_files_ = sorted(glob.glob(\"../processed_batches/train/*.pt\"), key=extract_file_numbers)\n",
    "    print()\n",
    "    print(f'training run from {train_files_[0]}')\n",
    "\n",
    "\n",
    "train_ds = PTIterableDataset(train_files_)\n",
    "train_loader = DataLoader(train_ds, batch_size=config.data_loader_batch_size, num_workers=0, drop_last=True)\n",
    "print(next(iter(train_loader)))\n",
    "print()\n",
    "\n",
    "create_repo_if_not_exists(config.checkpoint_repo, config.hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train();\n",
    "for epoch in range(config.num_epochs):\n",
    "    running_loss = 0 \n",
    "    for step, batch in enumerate(train_loader, start=1): \n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        current_file = set(batch['files'])\n",
    "\n",
    "        # forward pass (no autocast for CPU)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        raw_loss = outputs.loss\n",
    "\n",
    "        running_loss+=raw_loss.item()\n",
    "        loss = raw_loss/config.gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if step % config.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            lr_scheduler.step()\n",
    "            global_step+=1\n",
    "\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            effective_loss = running_loss/config.gradient_accumulation_steps\n",
    "            loss_history.append(effective_loss)\n",
    "            print(f\"Global step {global_step}, LR: {current_lr:.8f}, Loss: {effective_loss:.4f}\")\n",
    "            running_loss = 0 \n",
    "\n",
    "            if global_step % config.save_steps == 0:\n",
    "                save_checkpoint(\n",
    "                    model=model, \n",
    "                    optimizer=optimizer, \n",
    "                    lr_scheduler=lr_scheduler, \n",
    "                    global_step=global_step, \n",
    "                    loss_history=loss_history,\n",
    "                    last_file=current_file,\n",
    "                )\n",
    "                \n",
    "                print('saved checkpoint')\n",
    "                push_to_hub(\n",
    "                    repo_name=config.checkpoint_repo,\n",
    "                    token=config.hf_token,\n",
    "                    step=global_step,\n",
    "                    max_retries=3,\n",
    "                    retry_delay=10\n",
    "                )\n",
    "                print('hub push completed')\n",
    "\n",
    "# print('final model push...')\n",
    "# model.push_to_hub(config.checkpoint_repo, commit_message=f\"trained model at pass {epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Training Loop (FP16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train();\n",
    "for epoch in range(config.num_epochs):\n",
    "    running_loss = 0\n",
    "    for step, batch in enumerate(train_loader, start=1):\n",
    "        input_ids = batch['input_ids'].to(config.device)\n",
    "        attention_mask = batch['attention_mask'].to(config.device)\n",
    "        current_file = batch['files'][0]  # single filename for consistency\n",
    "\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "            raw_loss = outputs.loss\n",
    "\n",
    "        running_loss += raw_loss.item()\n",
    "        loss = raw_loss / config.gradient_accumulation_steps\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if step % config.gradient_accumulation_steps == 0:\n",
    "            # unscale, clip, step, update scaler & scheduler\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            lr_scheduler.step()\n",
    "            global_step += 1\n",
    "\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            effective_loss = running_loss / config.gradient_accumulation_steps\n",
    "            loss_history.append(effective_loss)\n",
    "            print(f\"Global step {global_step}, LR: {current_lr:.8f}, Loss: {effective_loss:.4f}\")\n",
    "            running_loss = 0\n",
    "\n",
    "            if global_step % config.save_steps == 0:\n",
    "                save_checkpoint(\n",
    "                    model=model,\n",
    "                    optimizer=optimizer,\n",
    "                    lr_scheduler=lr_scheduler,\n",
    "                    global_step=global_step,\n",
    "                    loss_history=loss_history,\n",
    "                    last_file=current_file,\n",
    "                    scaler=scaler\n",
    "                )\n",
    "                print('saved checkpoint')\n",
    "                push_to_hub(\n",
    "                    repo_name=config.checkpoint_repo,\n",
    "                    token=config.hf_token,\n",
    "                    step=global_step\n",
    "                )\n",
    "                print('hub push completed')\n",
    "\n",
    "# print('final model push...')\n",
    "# model.push_to_hub(config.checkpoint_repo, commit_message=\"Final trained model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
