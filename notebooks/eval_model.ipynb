{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b954d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, glob, re\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import GPT2LMHeadModel\n",
    "from torch.utils.data import IterableDataset, DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "class PTIterableDataset(IterableDataset):\n",
    "    def __init__(self, pt_files):\n",
    "        self.pt_files = pt_files\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file_path in self.pt_files:\n",
    "            data = torch.load(file_path)\n",
    "            for i in range(data[\"input_ids\"].size(0)):\n",
    "                sample = {\n",
    "                    \"input_ids\": data[\"input_ids\"][i],\n",
    "                    \"attention_mask\": data[\"attention_mask\"][i],\n",
    "                    \"files\": file_path.split('/')[-1]\n",
    "                }\n",
    "                if data.get(\"labels\") is not None:\n",
    "                    sample[\"labels\"] = data[\"labels\"][i]\n",
    "                yield sample\n",
    "\n",
    "\n",
    "def extract_file_numbers(filename):\n",
    "    match = re.search(r'(\\d+)', filename)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "def evaluate_half(model, test_loader, total_steps, device):\n",
    "    model = model.half().to(device).eval()\n",
    "    torch.backends.cudnn.benchmark = True  # GPU kernel autotuning\n",
    "\n",
    "    total_loss = torch.tensor(0.0, device=device)\n",
    "    pbar = tqdm(test_loader, total=total_steps, desc=\"Evaluating\", unit=\"batch\")\n",
    "\n",
    "    with torch.inference_mode(): # lighter than no_grad()\n",
    "        for step, batch in enumerate(pbar, start=1):\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attn_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "\n",
    "            loss = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attn_mask,\n",
    "                labels=input_ids\n",
    "            ).loss\n",
    "\n",
    "            total_loss += loss\n",
    "            pbar.set_postfix(batch_loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    avg_loss   = total_loss / total_steps\n",
    "    print(step)\n",
    "    perplexity = torch.exp(avg_loss)\n",
    "\n",
    "    print(f\"Avg loss: {avg_loss:.4f}  â€”  Perplexity: {perplexity:.2f}\")\n",
    "    return avg_loss.item(), perplexity.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_batch_size = 16\n",
    "test_files_ = sorted(glob.glob(\"processed_batches/test/*.pt\"), key=extract_file_numbers)\n",
    "test_files_ = test_files_[:1000]\n",
    "test_ds = PTIterableDataset(test_files_)\n",
    "test_loader = DataLoader(test_ds, batch_size=loader_batch_size, num_workers=0, drop_last=True)\n",
    "\n",
    "# test_loader = DataLoader(test_ds, batch_size=loader_batch_size, num_workers=4, drop_last=True, pin_memory=True)\n",
    "print(next(iter(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test_tokens = len(test_files_) * 16 * 1024\n",
    "total_steps = total_test_tokens / (loader_batch_size * 1024)\n",
    "print(f\"{total_test_tokens:.2e} tokens\")\n",
    "print(f\"{total_steps} total_steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4976820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_id = 'cwestnedge/gpt2-small-pubmed'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "avg_loss, ppl = evaluate_half(model, test_loader, total_steps)\n",
    "print(f\"{model_id}: avg_loss = {avg_loss:.4f}, ppl = {ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9faaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'cwestnedge/gpt2-medium-pubmed'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "avg_loss, ppl = evaluate_half(model, test_loader, total_steps)\n",
    "print(f\"{model_id}: avg_loss = {avg_loss:.4f}, ppl = {ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c0fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'cwestnedge/gpt2-large-pubmed'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "avg_loss, ppl = evaluate_half(model, test_loader, total_steps)\n",
    "print(f\"{model_id}: avg_loss = {avg_loss:.4f}, ppl = {ppl:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
